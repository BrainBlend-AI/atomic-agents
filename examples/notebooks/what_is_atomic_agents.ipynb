{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Atomic Agents: Building AI with Modular Design\n",
    "\n",
    "Imagine building AI applications as easily as snapping together LEGO blocks. That's the idea behind [Atomic Agents](https://github.com/KennyVaneetvelde/atomic_agents), a new multi-agent framework inspired by **Atomic Design** principles.\n",
    "\n",
    "## Before we start, a brief background on Atomic Design\n",
    "\n",
    "First, let's talk about **Atomic Design**. Created by **Brad Frost**, it's a methodology for crafting design systems by breaking down interfaces into smaller, self-contained, reusable components. Think of it like atoms, molecules, and organisms in chemistry, but for UI design. This approach helps in creating scalable and consistent user interfaces while also allowing to modify/switch out any single part with minimal impact. Another analogy, as previously mentioned, is LEGO blocks where you can combine all the different, simple pieces to create something completely new and complex.\n",
    "\n",
    "## Why Atomic Agents?\n",
    "\n",
    "A lot of existing frameworks and methodologies for **Agentic AI** are focused on building autonomous multi-agent systems that you basically wind up and let go. While these can be fun to demo, they're not always practical for real-world applications. Real-life companies aren't looking for a bot that writes articles in a different style each time, with a different structure and a different tone. They want a bot that can write articles in a consistent style, with a consistent structure and a consistent tone that aligns with their brand. Beside fine-tuning a model, which requires a lot of data and money, and isn't even possible if you really want to use the latest GPT model, there's no practical way to gain full control of the output of these frameworks.\n",
    "\n",
    "In business, management rarely allocates budget just to create something that's cool but has no value. They want to see a return on investment. They want to see real business issues being solved and automated and cut costs. To achieve this, you need **modularity**, you need to be able to control the output, make sure it's not a black box, make the output reproducible, and make it reliable. This is where **Atomic Agents** come in.\n",
    "\n",
    "So how are these business problems solved traditionally, pre-AI? Well, before we even start writing code, we usually start with flows, user stories, customer journeys, ... and then we start breaking these down into smaller parts. We then start writing the necessary code. We'll have a function that takes in some input, processes it, and returns some output. We'll have another function that takes in that output, processes it, and stores it in a database. We'll have another function that queries the database, processes the data, and returns it to the user. The aim of **Atomic Agents** is to bring this same level of modularity and predictability to AI agent development.\n",
    "\n",
    "In other words, we are not looking to build \"An AI system that writes a blogpost\". We are looking for something highly structured and verbose. Specifically, we want to build an AI system that:\n",
    "\n",
    "1. Generates queries related to a subject\n",
    "2. Identifies the top X most relevant articles\n",
    "3. Visits each identified article's page\n",
    "4. Extracts the text from each article\n",
    "5. Generates a summary of each article\n",
    "6. Stores the summaries in a vector database\n",
    "7. Generates X questions around the subject\n",
    "8. Uses the vector database to answer those questions\n",
    "9. Re-synthesizes the answers into a coherent blogpost\n",
    "\n",
    "This approach; while being a lot more verbose, is also a lot more predictable, reliable, and, more importantly, usable in a real-world business.\n",
    "\n",
    "On top of that, we want to be able to fine-tune each individual step of that system if necessary, we want to be able to modify the system prompt for each task individually, be able to modify which tools are used, and how they are used, be able to choose where memory or context is shared, ... This is where **Atomic Agents** come in.\n",
    "\n",
    "## Anatomy of an Agent\n",
    "\n",
    "AI agents, not just in the **Atomic Agents** framework, take input from several sources, such as the **system prompt**, the **user input**, the (optionally) **available tools**, and **memory**. Within **Atomic Agents**, I wanted the developer to have full control over how each of these affects the output. This is why each of these are separate components within the framework. In developer terms, we speak of \"separation of concerns\" and \"single responsibility principle\" here.\n",
    "\n",
    "![Anatomy of an Atomic Agent](../../.assets/what_is_sent_in_prompt.png)\n",
    "\n",
    "In the diagram above, you can see the different components that make up an **Atomic Agent**. Each agent has a \"run\" method, an input schema and an output schema, each with their own schema descriptions, property descriptions, ... all defined by the developer using **Pydantic models**. This enables us to dynamically generate the input to the agent, and to validate its output. This is important because it allows us to chain agents together effortlessly, all the while ensuring that the output of one agent is the correct input for the next agent. Thus, in the schema all the green boxes are things that are always sent to the agent, the blue boxes are sent to the agent in the case where Agent1 is chained to Agent2, and Agent1 must generate output using the input schema of Agent2.\n",
    "\n",
    "Tools have almost the exact same setup, each tool has an input schema, an output schema, and a \"run\" method. This allows us to largely treat tools and agents the same way, and to chain them together in the same way. This is in line with a personal philosophy of mine that, at least until we reach AGI, we should treat AI agents as very advanced text-processing tools that are part of a bigger pipeline, rather than as a completely new paradigm (See [my article on Defensive & Robust design in AI automation](https://medium.com/@kenny_v/defensive-and-robust-design-in-ai-automation-8e951c8e7fd7)).\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "The real fun begins when you start chaining the input and output of different tools and agents together. By simply assigning the output schema of an agent to be the input schema to a tool, or to another agent, you can create complex AI applications that are still modular and easy to understand. If at any later point you change the tool, and change the schema, the entire system will still work without needing to change anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Building a simple AI agent\n",
    "Now that we've covered the basics, let's build a simple AI agent using **Atomic Agents** and examine how it works under the hood.\n",
    "\n",
    "First, we need to install the Atomic Agents package. You can do this by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: atomic-agents in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (0.1.45)\n",
      "Requirement already satisfied: openai in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (1.35.12)\n",
      "Requirement already satisfied: instructor in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (1.3.4)\n",
      "Requirement already satisfied: aiohttp in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from atomic-agents) (3.9.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from atomic-agents) (4.12.3)\n",
      "Requirement already satisfied: huggingface-hub in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from atomic-agents) (0.23.4)\n",
      "Requirement already satisfied: scikit-learn in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from atomic-agents) (1.5.1)\n",
      "Requirement already satisfied: sympy in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from atomic-agents) (1.13.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from instructor) (0.16)\n",
      "Requirement already satisfied: jiter<0.5.0,>=0.4.1 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from instructor) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from instructor) (2.20.1)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from instructor) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from instructor) (8.5.0)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from instructor) (0.12.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from aiohttp->atomic-agents) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from aiohttp->atomic-agents) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from aiohttp->atomic-agents) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from aiohttp->atomic-agents) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from aiohttp->atomic-agents) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from aiohttp->atomic-agents) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.8 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->instructor) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->instructor) (2.18.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from typer<1.0.0,>=0.9.0->instructor) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from typer<1.0.0,>=0.9.0->instructor) (1.5.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from beautifulsoup4->atomic-agents) (2.5)\n",
      "Requirement already satisfied: filelock in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from huggingface-hub->atomic-agents) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from huggingface-hub->atomic-agents) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from huggingface-hub->atomic-agents) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from huggingface-hub->atomic-agents) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from huggingface-hub->atomic-agents) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from scikit-learn->atomic-agents) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from scikit-learn->atomic-agents) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from scikit-learn->atomic-agents) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from scikit-learn->atomic-agents) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from sympy->atomic-agents) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from requests->huggingface-hub->atomic-agents) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/w3bwizar/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages (from requests->huggingface-hub->atomic-agents) (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install atomic-agents openai instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or better yet, you can clone the repository from [here](https://github.com/KennyVaneetvelde/atomic_agents) and help me improve it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will import the necessary components for creating the chatbot. Each component serves a specific purpose:\n",
    "- `AgentMemory`: Manages the chat history.\n",
    "- `BaseChatAgent`: The base class to create a custom chatbot. Can be extended for additional functionality if needed.\n",
    "- `SystemPromptGenerator` and `SystemPromptInfo`: To define and generate system prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the system prompt information including background, steps, and output instructions. In this example, we will define a system prompt that asks the chatbot to respond to user inputs in rhyming verse.\n",
    "\n",
    "The structuring of the system prompts in this library is loosely inspired by the concept of **Patterns** in the [Fabric library](https://github.com/danielmiessler/fabric/tree/main/patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># IDENTITY and PURPOSE\n",
       "- This assistant is a general-purpose AI designed to be helpful and friendly.\n",
       "\n",
       "# INTERNAL ASSISTANT STEPS\n",
       "- Understand the user's input and provide a relevant response.\n",
       "- Respond to the user.\n",
       "\n",
       "# OUTPUT INSTRUCTIONS\n",
       "- Provide helpful and relevant information to assist the user.\n",
       "- Be friendly and respectful in all interactions.\n",
       "- Always answer in rhyming verse.\n",
       "- Always respond using the proper JSON schema.\n",
       "- Always use the available additional information and context to enhance the response.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# IDENTITY and PURPOSE\n",
       "- This assistant is a general-purpose AI designed to be helpful and friendly.\n",
       "\n",
       "# INTERNAL ASSISTANT STEPS\n",
       "- Understand the user's input and provide a relevant response.\n",
       "- Respond to the user.\n",
       "\n",
       "# OUTPUT INSTRUCTIONS\n",
       "- Provide helpful and relevant information to assist the user.\n",
       "- Be friendly and respectful in all interactions.\n",
       "- Always answer in rhyming verse.\n",
       "- Always respond using the proper JSON schema.\n",
       "- Always use the available additional information and context to enhance the response.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "\n",
    "system_prompt = SystemPromptInfo(\n",
    "    background=[\n",
    "        'This assistant is a general-purpose AI designed to be helpful and friendly.',\n",
    "    ],\n",
    "    steps=[\n",
    "        'Understand the user\\'s input and provide a relevant response.',\n",
    "        'Respond to the user.'\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        'Provide helpful and relevant information to assist the user.',\n",
    "        'Be friendly and respectful in all interactions.',\n",
    "        'Always answer in rhyming verse.'\n",
    "    ]\n",
    ")\n",
    "system_prompt_generator = SystemPromptGenerator(system_prompt)\n",
    "\n",
    "Console().print(system_prompt_generator.generate_prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have generated the following system prompt:\n",
    "\n",
    "``` markdown\n",
    "# IDENTITY and PURPOSE\n",
    "- This assistant is a general-purpose AI designed to be helpful and friendly.\n",
    "\n",
    "# INTERNAL ASSISTANT STEPS\n",
    "- Understand the user's input and provide a relevant response.\n",
    "- Respond to the user.\n",
    "\n",
    "# OUTPUT INSTRUCTIONS\n",
    "- Provide helpful and relevant information to assist the user.\n",
    "- Be friendly and respectful in all interactions.\n",
    "- Always answer in rhyming verse.\n",
    "- Always respond using the proper JSON schema.\n",
    "- Always use the available additional information and context to enhance the response.\n",
    "```\n",
    "\n",
    "Note how the last two output instructions are not part of the developer's specification, but are automatically added by the framework to increase reliability in the system prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the system prompt, and thus essentially the behavior and purpose of the chatbot, it makes sense to define an initial memory with a message from the assistant to the user. This step is completely optional however as the `BaseChatAgent` that we will be using later has a check for this and will automatically create an empty memory if none is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atomic_agents.lib.components.agent_memory import AgentMemory\n",
    "\n",
    "memory = AgentMemory()\n",
    "initial_memory = [\n",
    "    {'role': 'assistant', 'content': 'How do you do? What can I do for you? Tell me, pray, what is your need today?'}\n",
    "]\n",
    "memory.load(initial_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create a custom chatbot. Either by using the `BaseChatAgent` class, or by extending it. Since this is a simple usecase, let's look at what it will look like if we simply use the class. In the code below, you can either specify your API key directly in the code or use an environment variable to store it.\n",
    "\n",
    "In this instance, I will use the OpenAI client with gpt-3.5-turbo. However, you can choose other clients such as **Anthropic**, **Mistral**, **Groq**, etc... For a full list, check out the [Instructor library docs](https://github.com/jxnl/instructor). Changing the client is as simple as changing the import statement, defining the client, and changing the `model` parameter to a model that is supported by that client (so, for example `llama3-70b-8192` on **Groq**)\n",
    "\n",
    "First, we'll set up the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''\n",
    "if not API_KEY:\n",
    "    # Get the environment variable\n",
    "    API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError('API key is not set. Please set the API key as a static variable or in the environment variable OPENAI_API_KEY.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up the patched `Instructor` client. This is what takes the `Pydantic` models and uses them for input validation and output generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import openai\n",
    "from atomic_agents.agents.base_chat_agent import BaseChatAgent, BaseChatAgentConfig\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI(api_key=API_KEY))\n",
    "\n",
    "agent = BaseChatAgent(\n",
    "    config=BaseChatAgentConfig(\n",
    "        client=client,\n",
    "        system_prompt_generator=system_prompt_generator,\n",
    "        model='gpt-3.5-turbo',\n",
    "        memory=memory,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Groq, for example would look like this:\n",
    "# import groq\n",
    "# client = instructor.from_groq(groq.Client(api_key=[YOUR API KEY]))\n",
    "# agent = BaseChatAgent(\n",
    "#     config=BaseChatAgentConfig(\n",
    "#         model='llama3-70b-8192',\n",
    "#         ...\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run the chatbot. Let's start by printing the initial message, followed by a simple chat-loop. Personally, I like to have /exit and /quit as commands to exit the chatbot, but you can change this to whatever you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: How do you do? What can I do for you? Tell me, pray, what is your need today?\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting chat...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mchat_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/atomic_agents/agents/base_chat_agent.py:149\u001b[0m, in \u001b[0;36mBaseChatAgent.run\u001b[0;34m(self, user_input)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_run(user_input)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_run()\n\u001b[0;32m--> 149\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_and_handle_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_run(response)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/atomic_agents/agents/base_chat_agent.py:160\u001b[0m, in \u001b[0;36mBaseChatAgent._get_and_handle_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_and_handle_response\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Handles obtaining and processing the response.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m        Type[BaseModel]: The processed response.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/atomic_agents/agents/base_chat_agent.py:133\u001b[0m, in \u001b[0;36mBaseChatAgent.get_response\u001b[0;34m(self, response_model)\u001b[0m\n\u001b[1;32m    125\u001b[0m     response_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_schema\n\u001b[1;32m    127\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    128\u001b[0m     {\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem_prompt_generator\u001b[38;5;241m.\u001b[39mgenerate_prompt(),\n\u001b[1;32m    131\u001b[0m     }\n\u001b[1;32m    132\u001b[0m ] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mget_history()\n\u001b[0;32m--> 133\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/instructor/client.py:91\u001b[0m, in \u001b[0;36mInstructor.create\u001b[0;34m(self, response_model, messages, max_retries, validation_context, strict, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     82\u001b[0m     response_model: \u001b[38;5;28mtype\u001b[39m[T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T \u001b[38;5;241m|\u001b[39m Awaitable[T]:\n\u001b[1;32m     89\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_kwargs(kwargs)\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/instructor/patch.py:143\u001b[0m, in \u001b[0;36mpatch.<locals>.new_create_sync\u001b[0;34m(response_model, validation_context, max_retries, strict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_create_sync\u001b[39m(\n\u001b[1;32m    133\u001b[0m     response_model: \u001b[38;5;28mtype\u001b[39m[T_Model] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: T_ParamSpec\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_Model:\n\u001b[1;32m    140\u001b[0m     response_model, new_kwargs \u001b[38;5;241m=\u001b[39m handle_response_model(\n\u001b[1;32m    141\u001b[0m         response_model\u001b[38;5;241m=\u001b[39mresponse_model, mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    142\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mretry_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/instructor/retry.py:162\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m max_retries:\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m attempt:\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/tenacity/__init__.py:443\u001b[0m, in \u001b[0;36mBaseRetrying.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m AttemptManager(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/instructor/retry.py:165\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m attempt:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m         stream \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    167\u001b[0m         response \u001b[38;5;241m=\u001b[39m update_total_usage(response, total_usage)\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/openai/resources/chat/completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/openai/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/openai/_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/openai/_base_client.py:1031\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1030\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/openai/_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/openai/_base_client.py:1031\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1030\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/openai/_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/AI/atomic_agents/.venv/lib/python3.10/site-packages/openai/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1054\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "print(f'Agent: {initial_memory[0][\"content\"]}')\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    if user_input.lower() in ['/exit', '/quit']:\n",
    "        print('Exiting chat...')\n",
    "        break\n",
    "    \n",
    "    response = agent.run(agent.input_schema(chat_message=user_input))\n",
    "    print(f'Agent: {response.chat_message}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behind the scenes\n",
    "\n",
    "So, what is happening behind the scenes when we run the chatbot? Let's dissect the `BaseChatAgent` and understand how it works.\n",
    "\n",
    "First off, as mentioned before, each tool and each agent has an **input schema** and an **output schema**.\n",
    "\n",
    "These schemas all extend from what is called the `BaseAgentIO` class. This class itself is a Pydantic model with some predefined methods to facilitate storing a structured response in memory and to facilitate printing the response to the console using the `rich` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from rich.json import JSON\n",
    "\n",
    "class BaseAgentIO(BaseModel):\n",
    "    \"\"\"\n",
    "    Base class for input and output schemas for chat agents.\n",
    "    \"\"\"\n",
    "    def __str__(self):\n",
    "        return self.model_dump_json()\n",
    "    \n",
    "    def __rich__(self):\n",
    "        json_str = self.model_dump_json()\n",
    "        return JSON(json_str)\n",
    "    \n",
    "class BaseChatAgentInputSchema(BaseAgentIO):\n",
    "    chat_message: str = Field(\n",
    "        ...,\n",
    "        description='The chat message exchanged between the user and the chat agent. '\n",
    "                    'This represents the message sent by the user.'\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        title = 'BaseChatAgentInputSchema'\n",
    "        description = 'This schema represents the user input message exchanged between the user and the chat agent.'\n",
    "        json_schema_extra = {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "        }\n",
    "\n",
    "class BaseChatAgentOutputSchema(BaseAgentIO):\n",
    "    chat_message: str = Field(\n",
    "        ...,\n",
    "        description='The chat message exchanged between the user and the chat agent. '\n",
    "                    'This contains the markdown-enabled response generated by the chat agent.'\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        title = 'BaseChatAgentOutputSchema'\n",
    "        description = 'This schema represents the response message exchanged between the user and the chat agent.'\n",
    "        json_schema_extra = {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, you can see that the `BaseChatAgentInputSchema` and `BaseChatAgentOutputSchema` both:\n",
    "- Extend from `BaseAgentIO`\n",
    "- Have a `chat_message` field with a `description` property \n",
    "- Have a Config class with a `title`, `description`, and `json_schema_extra` property.\n",
    "\n",
    "Let's analyze why these title and description properties are important, by looking at what will be presented to the LLM model when we run the chatbot. We can do this by simply dumping one of the schemas to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(BaseChatAgentOutputSchema.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output something like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"description\": \"This schema represents the response message exchanged between the user and the chat agent.\",\n",
    "  \"properties\": {\n",
    "    \"chat_message\": {\n",
    "      \"description\": \"The chat message exchanged between the user and the chat agent. This contains the markdown-enabled response generated by the chat agent.\",\n",
    "      \"title\": \"Chat Message\",\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\n",
    "    \"chat_message\"\n",
    "  ],\n",
    "  \"title\": \"BaseChatAgentOutputSchema\",\n",
    "  \"type\": \"object\"\n",
    "}\n",
    "```\n",
    "\n",
    "This is what the LLM model will see and be constricted by when generating a response. Additionally, this allows for easy generation of documentation as well since these properties are generally accepted by most documentation generators. For example by using [sphinx-pydantic](https://sphinx-pydantic.readthedocs.io/en/latest/).\n",
    "\n",
    "Thus, changing the title and description to be more clear, descriptive and precise is encouraged both to improve & fine-tune the agent's performance, but also to improve the documentation of the agent.\n",
    "\n",
    "Note that even though in the base chat agent both the input and output schemas have a `chat_message` field, this is not a requirement. We can easily specify any schema we like as the input or the output schema.\n",
    "\n",
    "For example, we can even have a nested schema with enums, lists, and more complex structures as demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class YelpCategory(Enum):\n",
    "    ITALIAN = \"italian\"\n",
    "    MEXICAN = \"mexican\"\n",
    "    PIZZA = \"pizza\"\n",
    "    SUSHI = \"sushi\"\n",
    "    CHINESE = \"chinese\"\n",
    "    INDIAN = \"indian\"\n",
    "    THAI = \"thai\"\n",
    "    FRENCH = \"french\"\n",
    "    GREEK = \"greek\"\n",
    "    JAPANESE = \"japanese\"\n",
    "    KOREAN = \"korean\"\n",
    "    VIETNAMESE = \"vietnamese\"\n",
    "    AMERICAN = \"american\"\n",
    "    BBQ = \"bbq\"\n",
    "    BURGERS = \"burgers\"\n",
    "    SEAFOOD = \"seafood\"\n",
    "    STEAKHOUSES = \"steakhouses\"\n",
    "    VEGAN = \"vegan\"\n",
    "    VEGETARIAN = \"vegetarian\"\n",
    "\n",
    "class PriceRange(Enum):\n",
    "    ONE = \"1\"\n",
    "    TWO = \"2\"\n",
    "    THREE = \"3\"\n",
    "    FOUR = \"4\"\n",
    "\n",
    "class YelpSearchToolSchema(BaseAgentIO):\n",
    "    location: str = Field(..., description=\"Location to search for food.\")\n",
    "    term: Optional[str] = Field(None, description=\"Search term (e.g., 'pizza', 'sushi').\")\n",
    "    categories: Optional[List[YelpCategory]] = Field(None, description=\"Categories to filter by (e.g., 'italian, mexican').\")\n",
    "    price: Optional[List[PriceRange]] = Field(None, description=\"Price range to filter by (e.g., '1', '2', '3', '4'). Can be multiple. 1 is cheap. 2 and 3 are mid-range. 4 is the most high-end.\")\n",
    "    open_now: Optional[bool] = Field(False, description=\"Filter for businesses that are open now.\")\n",
    "    limit: Optional[int] = Field(10, description=\"Number of results to return.\")\n",
    "\n",
    "    class Config:\n",
    "        title = \"YelpSearchTool\"\n",
    "        description = \"Tool for searching for food using the Yelp API. Returns a list of businesses with details such as name, rating, and address.\"\n",
    "        json_schema_extra = {\n",
    "            \"title\": title,\n",
    "            \"description\": description\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting things to note here:\n",
    "- The price ranges and categories are defined as an enum, which means that the only valid values are the ones specified in the enum.\n",
    "- The description of the `price_range` field lists what the values mean, which is important for the model to understand the context of the input. This essentially replaces the need for a prompt or few-show examples in the traditional sense.\n",
    "- If this is not sufficient, [Pydantic examples](https://docs.pydantic.dev/latest/concepts/fields/#customizing-json-schema) can still be added as well per property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the BaseChatAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import Field, create_model\n",
    "from atomic_agents.agents.base_chat_agent import BaseAgentIO, BaseChatAgent, BaseChatAgentConfig\n",
    "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptInfo\n",
    "from atomic_agents.lib.tools.base import BaseTool\n",
    "from atomic_agents.lib.utils.format_tool_message import format_tool_message\n",
    "\n",
    "class ToolInterfaceAgentConfig(BaseChatAgentConfig):\n",
    "    tool_instance: BaseTool\n",
    "    return_raw_output: bool = False\n",
    "\n",
    "class ToolInputModel(BaseAgentIO):\n",
    "    tool_input: str = Field(..., description=\"Tool input. Presented as a single question or instruction\")\n",
    "\n",
    "    class Config:\n",
    "        title = \"Default Tool\"\n",
    "        description = \"Default tool description\"\n",
    "        json_schema_extra = {\n",
    "            \"title\": \"Default Tool\",\n",
    "            \"description\": \"Default tool description\"\n",
    "        }\n",
    "\n",
    "class ToolInterfaceAgent(BaseChatAgent):\n",
    "    \"\"\"\n",
    "    A specialized chat agent designed to interact with a specific tool.\n",
    "\n",
    "    This agent extends the BaseChatAgent to include functionality for interacting with a tool instance.\n",
    "    It generates system prompts, handles tool input and output, and can optionally return raw tool output.\n",
    "\n",
    "    Attributes:\n",
    "        tool_instance: The instance of the tool this agent will interact with.\n",
    "        return_raw_output (bool): Whether to return the raw output from the tool.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ToolInterfaceAgentConfig):\n",
    "        \"\"\"\n",
    "        Initializes the ToolInterfaceAgent.\n",
    "\n",
    "        Args:\n",
    "            config (ToolInterfaceAgentConfig): Configuration for the tool interface agent.\n",
    "        \"\"\"\n",
    "        super().__init__(config=config)\n",
    "        \n",
    "        self.tool_instance = config.tool_instance\n",
    "        self.return_raw_output = config.return_raw_output\n",
    "        \n",
    "        # Create a new model with the updated schema\n",
    "        self.input_schema = create_model(\n",
    "            self.tool_instance.tool_name,\n",
    "            tool_input=(str, Field(..., description=f\"{self.tool_instance.tool_name} tool input. Presented as a single question or instruction\", alias=f'tool_input_{self.tool_instance.tool_name}')),\n",
    "            __base__=ToolInputModel\n",
    "        )\n",
    "        \n",
    "        # Manually set the configuration attributes\n",
    "        self.input_schema.model_config['title'] = self.tool_instance.tool_name\n",
    "        self.input_schema.model_config['description'] = self.tool_instance.tool_description\n",
    "        self.input_schema.model_config['json_schema_extra'] = {\n",
    "            'title': self.tool_instance.tool_name,\n",
    "            'description': self.tool_instance.tool_description\n",
    "        }\n",
    "        \n",
    "        if self.return_raw_output:\n",
    "            self.output_schema = self.tool_instance.output_schema\n",
    "            \n",
    "        self.system_prompt_generator = SystemPromptGenerator(\n",
    "            system_prompt_info=SystemPromptInfo(\n",
    "                background=[\n",
    "                    f\"This AI agent is designed to interact with the {self.tool_instance.tool_name} tool.\",\n",
    "                    f\"Tool description: {self.tool_instance.tool_description}\"\n",
    "                ],\n",
    "                steps=[\n",
    "                    \"Get the user input.\",\n",
    "                    \"Convert the input to the proper parameters to call the tool.\",\n",
    "                    \"Call the tool with the parameters.\",\n",
    "                    \"Respond to the user\"\n",
    "                ],\n",
    "                output_instructions=[\n",
    "                    \"Make sure the tool call will maximize the utility of the tool in the context of the user input.\",\n",
    "                    \"Process the output of the tool into a human readable format and/or use it to respond to the user input.\" if self.return_raw_output else \"Return the raw output of the tool.\"\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def _get_and_handle_response(self):\n",
    "        \"\"\"\n",
    "        Handles obtaining and processing the response from the tool.\n",
    "\n",
    "        This method gets the response from the tool, formats the tool input, adds it to memory,\n",
    "        runs the tool, and processes the tool output. If `return_raw_output` is True, it returns\n",
    "        the raw tool output; otherwise, it processes the output and returns the response.\n",
    "        \n",
    "        Returns:\n",
    "            BaseModel: The processed response or raw tool output.\n",
    "        \"\"\"\n",
    "        tool_input = self.get_response(response_model=self.tool_instance.input_schema)\n",
    "        formatted_tool_input = format_tool_message(tool_input)\n",
    "        \n",
    "        self.memory.add_message('assistant', 'TOOL CALL: ' + json.dumps(formatted_tool_input))\n",
    "        tool_output = self.tool_instance.run(tool_input)\n",
    "        self.memory.add_message('assistant', 'TOOL RESPONSE: ' + tool_output.model_dump_json())\n",
    "        \n",
    "        if self.return_raw_output:\n",
    "            return tool_output\n",
    "        \n",
    "        self.memory.add_message('assistant', 'I will now formulate a response for the user based on the tool output.')\n",
    "        response = self.get_response(response_model=self.output_schema)        \n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, another way to create a new agent is by extending the `BaseChatAgent` class. This allows for more flexibility and customization. Let's look at an example where we extend the `BaseChatAgent` class to create an agent of which the output will always match the required input for a tool. To achieve this and get both the tool call and tool response in the memory, we will want to override the method `_get_and_handle_response`. Additionally, we will want to generate the input schema **dynamically** in order to be able to use any tool we want with this new agent.\n",
    "\n",
    "A simple example of how to use this ToolInterfaceAgent could be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import instructor\n",
    "import openai\n",
    "from rich.console import Console\n",
    "\n",
    "from atomic_agents.agents.tool_interface_agent import ToolInterfaceAgent, ToolInterfaceAgentConfig\n",
    "from atomic_agents.lib.tools.search.searx_tool import SearxNGSearchTool, SearxNGSearchToolConfig\n",
    "\n",
    "def initialize_searx_tool():\n",
    "    \"\"\"\n",
    "    Initialize the SearxNGSearchTool with configuration.\n",
    "    \"\"\"\n",
    "    base_url = os.getenv('SEARXNG_BASE_URL')\n",
    "    config = SearxNGSearchToolConfig(base_url=base_url, max_results=10)\n",
    "    return SearxNGSearchTool(config)\n",
    "\n",
    "def initialize_agent(client, searx_tool):\n",
    "    \"\"\"\n",
    "    Initialize the ToolInterfaceAgent with the given client and SearxNGSearchTool.\n",
    "    \"\"\"\n",
    "    agent_config = ToolInterfaceAgentConfig(\n",
    "        client=client,\n",
    "        model='gpt-3.5-turbo',\n",
    "        tool_instance=searx_tool,\n",
    "        return_raw_output=False\n",
    "    )\n",
    "    return ToolInterfaceAgent(config=agent_config)\n",
    "\n",
    "def main():\n",
    "    console = Console()\n",
    "    client = instructor.from_openai(\n",
    "    openai.OpenAI(\n",
    "            base_url='http://localhost:1234/v1'\n",
    "        )\n",
    "    )\n",
    "    searx_tool = initialize_searx_tool()\n",
    "    agent = initialize_agent(client, searx_tool)\n",
    "\n",
    "    console.print(\"ToolInterfaceAgent with SearxNGSearchTool is ready.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input('You: ')\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print('Exiting chat...')\n",
    "            break\n",
    "        \n",
    "        # Fix this\n",
    "        response = agent.run(agent.input_schema(tool_input=user_input))\n",
    "        console.print(f'Agent: {response.chat_message}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "For now, that's it! While this guide is by no means complete, it should serve as a decent starting point for anyone looking to get started with **Atomic Agents**. If you have any questions, feel free to reach out to me! I'm always happy to help out and answer any questions you might have. If you want to contribute to the project, feel free to open a pull request on the [GitHub repository](https://github.com/KennyVaneetvelde/atomic_agents). Any help is greatly appreciated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If this article sparks your interest and you have any business inquiries, feel free to get in touch with me on [LinkedIn](https://www.linkedin.com/in/kennyvaneetvelde/). As an experienced life-long full-stack developer and course author with a grand fascination for what makes things tick and a love for AI that started in my early teens, I am absolutely certain I can assist with anything from coaching to product development to bespoke consultancy services."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
